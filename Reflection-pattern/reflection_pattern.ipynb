{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1bc453d-c8d3-4503-b3da-52120ad92c74",
   "metadata": {
    "tags": []
   },
   "source": [
    "# world of agents\n",
    "## Reflection Pattern\n",
    "\n",
    "The first pattern we are going to implement is the **reflection pattern**. \n",
    "\n",
    "This pattern allows the LLM to reflect and critique its outputs, following the next steps:\n",
    "\n",
    "1. The LLM **generates** a candidate output. If you look at the diagram above, it happens inside the **\"Generate\"** box.\n",
    "2. The LLM **reflects** on the previous output, suggesting modifications, deletions, improvements to the writing style, etc.\n",
    "3. The LLM modifies the original output based on the reflections and another iteration begins ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898c34d-de9a-4970-b7f4-3d86b69d45a7",
   "metadata": {},
   "source": [
    "## Generation Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4d7b7-40bf-43b9-a626-2a11d5529ac8",
   "metadata": {},
   "source": [
    "### dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01fdbf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install groq\n",
    "# pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96731d2f-a079-4e41-9756-220f02d4ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "# Remember to load the environment variables. You should have the Groq API Key in there :)\n",
    "load_dotenv()\n",
    "\n",
    "client = Groq()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e644a635-e035-44e2-8c25-cee0f2b56556",
   "metadata": {},
   "source": [
    "We will start the **\"generation\"** chat history with the system prompt, as we said before. In this case, let the LLM act like a mathematician."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12467256-c741-495a-9923-439c1fcf270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_chat_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a front end developer tasked with generating high quality Python code.\"\n",
    "        \"Your task is to Generate the best content possible for the user's request. If the user provides critique,\" \n",
    "        \"respond with a revised version of your previous attempt.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43149b4f-54db-455f-9d39-6ad2f5c52b94",
   "metadata": {},
   "source": [
    "Now, as the user, we are going to ask the LLM to generate an implementation of the **Merge Sort** algorithm. Just add a new message with the **user** role to the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0742e7bd-4857-4ed1-a96b-37098d448bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_chat_history.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Generate a Python implementation of front end web app like chatgpt\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df1bffe-375f-4a9a-8433-e217eb94aea2",
   "metadata": {},
   "source": [
    "Let's generate the first version of the essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff984277-733c-4495-b7fd-0669393380b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend_code = client.chat.completions.create(\n",
    "    messages=generation_chat_history,\n",
    "    model=\"llama3-70b-8192\"\n",
    ").choices[0].message.content\n",
    "\n",
    "generation_chat_history.append(\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": frontend_code\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03f208b-2234-4fd1-a02b-f4fff06c01a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Creating a full-fledged chatbot like ChatGPT in Python would require a significant amount of code and multiple components. However, I can provide a simplified implementation of a chatbot using Python's Flask framework for the backend and HTML/CSS/JavaScript for the user interface. This implementation will use a basic natural language processing (NLP) library called NLTK for text processing.\n",
       "\n",
       "**Please note that this is a simplified implementation and not a production-ready code.**\n",
       "\n",
       "**Backend (Python using Flask)**\n",
       "```python\n",
       "from flask import Flask, request, jsonify\n",
       "import nltk\n",
       "from nltk.tokenize import word_tokenize\n",
       "from nltk.corpus import stopwords\n",
       "from nltk.stem import WordNetLemmatizer\n",
       "\n",
       "app = Flask(__name__)\n",
       "\n",
       "lemmatizer = WordNetLemmatizer'\n",
       "stop_words = set(stopwords.words('english'))\n",
       "\n",
       "def process_text(text):\n",
       "    tokens = word_tokenize(text)\n",
       "    tokens = [token for token in tokens if token not in stop_words]\n",
       "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
       "    return ' '.join(tokens)\n",
       "\n",
       "@app.route('/chat', methods=['POST'])\n",
       "def chat():\n",
       "    data = request.get_json()\n",
       "    text = data['text']\n",
       "    processed_text = process_text(text)\n",
       "    response = f\"You said: {processed_text}\"\n",
       "    return jsonify({'response': response})\n",
       "\n",
       "if __name__ == '__main__':\n",
       "    app.run(debug=True)\n",
       "```\n",
       "**Frontend (HTML/CSS/JavaScript)**\n",
       "```html\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "    <title>Chatbot</title>\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "        }\n",
       "        #chat-window {\n",
       "            border: 1px solid #ccc;\n",
       "            padding: 10px;\n",
       "            width: 300px;\n",
       "            height: 300px;\n",
       "            overflow-y: scroll;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "    <h1>Chatbot</h1>\n",
       "    <div id=\"chat-window\">\n",
       "        <input type=\"text\" id=\"chat-input\" placeholder=\"Type something...\">\n",
       "        <button id=\"send-btn\">Send</div>\n",
       "    </div>\n",
       "    <script>\n",
       "        const chatWindow = document.getElementById('chat-window');\n",
       "        const chatInput = document.getElementById('chat-input');\n",
       "        const sendBtn = document.getElementById('send-btn');\n",
       "\n",
       "        sendBtn.addEventListener('click', async () => {\n",
       "            const text = chatInput.value.trim();\n",
       "            if (text) {\n",
       "                const response = await fetch('/chat', {\n",
       "                    method: 'POST',\n",
       "                    headers: {\n",
       "                        'Content-Type': 'application/json'\n",
       "                    },\n",
       "                    body: JSON.stringify({ text })\n",
       "                });\n",
       "                const data = await response.json();\n",
       "                const responseText = document.createElement('p');\n",
       "                responseText.textContent = data.response;\n",
       "                chatWindow.appendChild(responseText);\n",
       "                chatInput.value = '';\n",
       "            }\n",
       "        });\n",
       "    </script>\n",
       "</body>\n",
       "</html>\n",
       "```\n",
       "**How it works**\n",
       "\n",
       "1. The user types a message in the text input field and clicks the \"Send\" button.\n",
       "2. The JavaScript code sends a POST request to the Flask backend with the user's input text.\n",
       "3. The Flask backend receives the request, processes the text using the `process_text` function, and returns a response to the user.\n",
       "4. The JavaScript code receives the response from the backend and appends it to the chat window.\n",
       "\n",
       "**Limitations**\n",
       "\n",
       "* This implementation does not use a sophisticated NLP library like Transformers) for text processing.\n",
       "* The chatbot does not have a conversational flow or context; it simply responds to individual inputs.\n",
       "* The frontend does not have any error handling or validation.\n",
       "\n",
       "This is a basic implementation, and there are many ways to enhance it. If you provide feedback on this implementation, I can revise and improve it."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(frontend_code, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a33a2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are a front end developer tasked with generating high quality Python code.Your task is to Generate the best content possible for the user's request. If the user provides critique,respond with a revised version of your previous attempt.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Generate a Python implementation of front end web app like chatgpt'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Creating a full-fledged chatbot like ChatGPT in Python would require a significant amount of code and multiple components. However, I can provide a simplified implementation of a chatbot using Python\\'s Flask framework for the backend and HTML/CSS/JavaScript for the user interface. This implementation will use a basic natural language processing (NLP) library called NLTK for text processing.\\n\\n**Please note that this is a simplified implementation and not a production-ready code.**\\n\\n**Backend (Python using Flask)**\\n```python\\nfrom flask import Flask, request, jsonify\\nimport nltk\\nfrom nltk.tokenize import word_tokenize\\nfrom nltk.corpus import stopwords\\nfrom nltk.stem import WordNetLemmatizer\\n\\napp = Flask(__name__)\\n\\nlemmatizer = WordNetLemmatizer\\'\\nstop_words = set(stopwords.words(\\'english\\'))\\n\\ndef process_text(text):\\n    tokens = word_tokenize(text)\\n    tokens = [token for token in tokens if token not in stop_words]\\n    tokens = [lemmatizer.lemmatize(token) for token in tokens]\\n    return \\' \\'.join(tokens)\\n\\n@app.route(\\'/chat\\', methods=[\\'POST\\'])\\ndef chat():\\n    data = request.get_json()\\n    text = data[\\'text\\']\\n    processed_text = process_text(text)\\n    response = f\"You said: {processed_text}\"\\n    return jsonify({\\'response\\': response})\\n\\nif __name__ == \\'__main__\\':\\n    app.run(debug=True)\\n```\\n**Frontend (HTML/CSS/JavaScript)**\\n```html\\n<!DOCTYPE html>\\n<html>\\n<head>\\n    <title>Chatbot</title>\\n    <style>\\n        body {\\n            font-family: Arial, sans-serif;\\n        }\\n        #chat-window {\\n            border: 1px solid #ccc;\\n            padding: 10px;\\n            width: 300px;\\n            height: 300px;\\n            overflow-y: scroll;\\n        }\\n    </style>\\n</head>\\n<body>\\n    <h1>Chatbot</h1>\\n    <div id=\"chat-window\">\\n        <input type=\"text\" id=\"chat-input\" placeholder=\"Type something...\">\\n        <button id=\"send-btn\">Send</div>\\n    </div>\\n    <script>\\n        const chatWindow = document.getElementById(\\'chat-window\\');\\n        const chatInput = document.getElementById(\\'chat-input\\');\\n        const sendBtn = document.getElementById(\\'send-btn\\');\\n\\n        sendBtn.addEventListener(\\'click\\', async () => {\\n            const text = chatInput.value.trim();\\n            if (text) {\\n                const response = await fetch(\\'/chat\\', {\\n                    method: \\'POST\\',\\n                    headers: {\\n                        \\'Content-Type\\': \\'application/json\\'\\n                    },\\n                    body: JSON.stringify({ text })\\n                });\\n                const data = await response.json();\\n                const responseText = document.createElement(\\'p\\');\\n                responseText.textContent = data.response;\\n                chatWindow.appendChild(responseText);\\n                chatInput.value = \\'\\';\\n            }\\n        });\\n    </script>\\n</body>\\n</html>\\n```\\n**How it works**\\n\\n1. The user types a message in the text input field and clicks the \"Send\" button.\\n2. The JavaScript code sends a POST request to the Flask backend with the user\\'s input text.\\n3. The Flask backend receives the request, processes the text using the `process_text` function, and returns a response to the user.\\n4. The JavaScript code receives the response from the backend and appends it to the chat window.\\n\\n**Limitations**\\n\\n* This implementation does not use a sophisticated NLP library like Transformers) for text processing.\\n* The chatbot does not have a conversational flow or context; it simply responds to individual inputs.\\n* The frontend does not have any error handling or validation.\\n\\nThis is a basic implementation, and there are many ways to enhance it. If you provide feedback on this implementation, I can revise and improve it.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04ebe5-0573-4520-a529-aff22d486b7d",
   "metadata": {},
   "source": [
    "## Reflection Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d93c928-d585-48af-a74c-a5b8d84593c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reflection_chat_history = [\n",
    "    {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You ar  an experienced frontend devloper. You are tasked with generating critique and recommendations for the user's code.\"\n",
    "    \"make sure to code the certain task only without any additions like adding irrelavnt features,\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498175f-b3f9-40af-92a3-d5b36d77d1cf",
   "metadata": {},
   "source": [
    "The user message, in this case,  is the essay generated in the previous step. We simply add the `mergesort_code` to the `reflection_chat_history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26af1a73-4d91-40e8-a9bc-c34d32b2ab82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reflection_chat_history.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": frontend_code\n",
    "\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa994c8-3612-47b0-9571-e21d0d73d896",
   "metadata": {},
   "source": [
    "Now, let's generate a critique to the Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40fee42f-d47a-41b1-a40d-7208ba76ce98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "critique = client.chat.completions.create(\n",
    "    messages=reflection_chat_history,\n",
    "    model=\"llama3-70b-8192\"\n",
    ").choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fef3203-c7f1-407f-8b9b-4e8ae140a4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a constructive critique of the provided code:\n",
       "\n",
       "**Backend (Python using Flask)**\n",
       "\n",
       "1. **Minor syntax error**: There is a syntax error in the line `lemmatizer = WordNetLemmatizer'`. It should be `lemmatizer = WordNetLemmatizer()`.\n",
       "\n",
       "2. **Global variables**: The `lemmatizer` and `stop_words` variables are defined globally. It's a good practice to define them inside the `process_text` function to reduce the global namespace.\n",
       "\n",
       "3. **Function naming**: The `process_text` function is doing more than just processing text. It's tokenizing, removing stop words, and lemmatizing. Consider renaming it to something like `preprocess_text`.\n",
       "\n",
       "4. **Response formatting**: The response is currently a simple string that includes the processed text. Consider formatting the response to include more information, such as the original text, processed text, and any additional metadata.\n",
       "\n",
       "5. **Error handling**: There is no error handling in the backend. Consider adding try-except blocks to handle potential errors, such as invalid input or NLTK library issues.\n",
       "\n",
       "**Frontend (HTML/CSS/JavaScript)**\n",
       "\n",
       "1. **HTML structure**: The HTML structure is not fully correct. The button element is not closed correctly. It should be `</button>` instead of `</div>`.\n",
       "\n",
       "2. **JavaScript variable naming**: The variable names `chatWindow`, `chatInput`, and `sendBtn` are not following a consistent naming convention. Consider using camelCase or underscore notation for consistency.\n",
       "\n",
       "4. **Error handling**: Similar to the backend, there is no error handling in the frontend. Consider adding try-catch blocks to handle potential errors, such as network errors or invalid responses from the backend.\n",
       "\n",
       "**General suggestions**\n",
       "\n",
       "1. **Separation of concerns**: The chatbot's logic is currently tightly coupled between the frontend and backend. Consider separating the concerns into distinct modules or classes to improve maintainability and scalability.\n",
       "\n",
       "3. **Testing**: There are no tests provided for the chatbot's functionality. Write unit tests and integration tests to ensure the chatbot works as expected.\n",
       "\n",
       "4. **Scalability**: The current implementation is quite basic and might not scale for large conversations or complex NLP tasks. Research and explore more advanced NLP libraries and chatbot architectures for scalability.\n",
       "\n",
       "5. **Code organization**: The code is not organized into separate files or modules. Consider breaking down the code into smaller, reusable components to improve maintainability and scalability.\n",
       "\n",
       "Here is the corrected and improved code based on the above suggestions:\n",
       "\n",
       "**Backend (Python using Flask)**\n",
       "```python\n",
       "from flask import Flask, request, jsonify\n",
       "import nltk\n",
       "from nltk.tokenize import word_tokenize\n",
       "from nltk.corpus import stopwords\n",
       "from nltk.stem import WordNetLemmatizer\n",
       "\n",
       "app = Flask(__name__)\n",
       "\n",
       "def preprocess_text(text):\n",
       "    stop_words = set(stopwords.words('english'))\n",
       "    lemmatizer = WordNetLemmatizer()`\n",
       "\n",
       "    tokens = word_tokenize(text)\n",
       "    tokens = [token for token in tokens if token not in stop_words]\n",
       "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
       "    return {'original_text': text, 'processed_text': ' '.join(tokens)}\n",
       "\n",
       "@app.route('/chat', methods=['POST'])\n",
       "def chat():\n",
       "    try:\n",
       "        data = request.get_json()\n",
       "        response = preprocess_text(data['text'])\n",
       "        return jsonify({'response': response})\n",
       "    except Exception as e:\n",
       "        return jsonify({'error': str(e)}))\n",
       "\n",
       "if __name__ == '__main__':\n",
       "    app.run(debug=True)\n",
       "```\n",
       "\n",
       "**Frontend (HTML/CSS/JavaScript)**\n",
       "```html\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "    <title>Chatbot</title>\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "        }\n",
       "        #chat-window {\n",
       "            border: 1px solid #ccc;\n",
       "            padding: 10px;\n",
       "            width: 300px;\n",
       "            height: 300px;\n",
       "            overflow-y: scroll;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "    <h1>Chatbot</h1>\n",
       "    <div id=\"chat-window\">\n",
       "        <input type=\"text\" id=\"chat-input\" placeholder=\"Type something...\">\n",
       "        <button id=\"send-btn\">Send</button>\n",
       "    </div>\n",
       "    <script>\n",
       "        const chatWindow = document.getElementById('chat-window');\n",
       "        const chatInput = document.getElementById('chat-input');\n",
       "        const sendBtn = document.getElementById('send-btn');\n",
       "\n",
       "        sendBtn.addEventListener('click', async () => {\n",
       "            try {\n",
       "                const text = chatInput.value.trim();\n",
       "                if (text) {\n",
       "                    const response = await fetch('/chat', {\n",
       "                        method: 'POST',\n",
       "                        headers: {\n",
       "                            'Content-Type': 'application/json'\n",
       "                        },\n",
       "                        body: JSON.stringify({ text })\n",
       "                    });\n",
       "                    const data = await response.json();\n",
       "                    const responseText = document.createElement('p');\n",
       "                    responseText.textContent = `Original: ${data.response.original_text}, Processed: ${data.response.processed_text}`;\n",
       "                    chatWindow.appendChild(responseText);\n",
       "                    chatInput.value = '';\n",
       "                }\n",
       "            } catch (error) {\n",
       "                console.error(error);\n",
       "            }\n",
       "        });\n",
       "    </script>\n",
       "</body>\n",
       "</html>\n",
       "```\n",
       "Remember, this is still a basic implementation, and there are many ways to enhance it."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(critique, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df433b0-d662-4378-895e-6b09dd3201bc",
   "metadata": {},
   "source": [
    "Finally, we just need to add this *critique* to the `generation_chat_history`, in this case, as the `user` role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27a85bb3-cf6a-4576-8caf-cd41e602a1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_chat_history.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": critique\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1aefa-8454-41ab-af40-2675f340a577",
   "metadata": {},
   "source": [
    "## Generation Step (II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d845cf-51c3-4cfd-b6a7-1b970413f6db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "revised_code = client.chat.completions.create(\n",
    "    messages=generation_chat_history,\n",
    "    model=\"llama3-70b-8192\"\n",
    ").choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef14eaa8-f501-4efc-997f-8564ec8dccd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Thank you for the detailed feedback! I apologize for the mistakes in my previous response.\n",
       "\n",
       "I've incorporated your suggestions and corrections into the code. Here's the revised implementation:\n",
       "\n",
       "**Backend (Python)**\n",
       "```python\n",
       "from flask import Flask, request, jsonify\n",
       "import nltk\n",
       "from nltk.tokenize import word_tokenize\n",
       "from nltk.corpus import stopwords\n",
       "from nltk.stem import WordNetLemmatizer\n",
       "\n",
       "app = Flask(__name__)\n",
       "\n",
       "def preprocess_text(text):\n",
       "    stop_words = set(stopwords.words('english'))\n",
       "    lemmatizer = WordNetLemmatizer()\n",
       "\n",
       "    tokens = word_tokenize(text)\n",
       "    tokens = [token for token in tokens if token not in stop_words]\n",
       "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
       "    return {'original_text': text, 'processed_text': ' '.join(tokens)}\n",
       "\n",
       "@app.route('/chat', methods=['POST'])\n",
       "def chat():\n",
       "    try:\n",
       "        data = request.get_json()\n",
       "        response = preprocess_text(data['text'])\n",
       "        return jsonify({'response': response})\n",
       "    except Exception as e:\n",
       "        return jsonify({'error': str(e)})\n",
       "\n",
       "if __name__ == '__main__':\n",
       "    app.run(debug=True)\n",
       "```\n",
       "\n",
       "**Frontend (HTML/CSS/JavaScript)**\n",
       "```html\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "    <title>Chatbot</title>\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "        }\n",
       "        #chat-window {\n",
       "            border: 1px solid #ccc;\n",
       "            padding: 10px;\n",
       "            width: 300px;\n",
       "            height: 300px;\n",
       "            overflow-y: scroll;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "    <h1>Chatbot</h1>\n",
       "    <div id=\"chat-window\">\n",
       "        <input type=\"text\" id=\"chat-input\" placeholder=\"Type something...\">\n",
       "        <button id=\"send-btn\">Send</button>\n",
       "    </div>\n",
       "    <script>\n",
       "        const chatWindow = document.getElementById('chat-window');\n",
       "        const chatInput = document.getElementById('chat-input');\n",
       "        const sendBtn = document.getElementById('send-btn');\n",
       "\n",
       "        sendBtn.addEventListener('click', async () => {\n",
       "            try {\n",
       "                const text = chatInput.value.trim();\n",
       "                if (text) {\n",
       "                    const response = await fetch('/chat', {\n",
       "                        method: 'POST',\n",
       "                        headers: {\n",
       "                            'Content-Type': 'application/json'\n",
       "                        },\n",
       "                        body: JSON.stringify({ text })\n",
       "                    });\n",
       "                    const data = await response.json();\n",
       "                    const responseText = document.createElement('p');\n",
       "                    responseText.textContent = `Original: ${data.response.original_text}, Processed: ${data.response.processed_text}`;\n",
       "                    chatWindow.appendChild(responseText);\n",
       "                    chatInput.value = '';\n",
       "                }\n",
       "            } catch (error) {\n",
       "                console.error(error);\n",
       "            }\n",
       "        });\n",
       "    </script>\n",
       "</body>\n",
       "</html>\n",
       "```\n",
       "I've addressed the following issues:\n",
       "\n",
       "1. Fixed the syntax error in the `WordNetLemmatizer` line.\n",
       "2. Moved the `lemmatizer` and `stop_words` variables inside the `preprocess_text` function.\n",
       "3. Renamed the `process_text` function to `preprocess_text`.\n",
       "4. Improved the response formatting to include original and processed text.\n",
       "5. Added error handling in both the frontend and backend.\n",
       "\n",
       "Your feedback is invaluable, and I appreciate your suggestions for improvement."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(revised_code, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2cf5b-d083-435c-914a-3ff484d53473",
   "metadata": {},
   "source": [
    "## Implementing a class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9a9e6-29f3-4adf-863e-c49fbb9a6b44",
   "metadata": {},
   "source": [
    "Now that you understand the underlying loop of the Reflection Agent, let's implement this agent as a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1658b881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 70E8-0B08\n",
      "\n",
      " Directory of c:\\Users\\moman\\OneDrive\\Desktop\\agents\\Reflection_agent\\agentic-patterns\\Reflection-pattern\n",
      "\n",
      "09/05/2025  05:54 PM    <DIR>          .\n",
      "09/05/2025  05:54 PM    <DIR>          ..\n",
      "08/05/2025  06:53 PM                73 .env\n",
      "09/05/2025  05:50 PM                 4 .gitignore\n",
      "09/05/2025  05:55 PM                34 __init__.py\n",
      "09/05/2025  05:55 PM            26,976 reflection_pattern.ipynb\n",
      "09/05/2025  05:42 PM    <DIR>          src\n",
      "09/05/2025  05:42 PM    <DIR>          utils\n",
      "               4 File(s)         27,087 bytes\n",
      "               4 Dir(s)   1,288,163,328 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f951fe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'Reflection_agent'\n",
      "c:\\Users\\moman\\OneDrive\\Desktop\\agents\\Reflection_agent\\agentic-patterns\\Reflection-pattern\n"
     ]
    }
   ],
   "source": [
    "cd Reflection_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f904241-29a1-4519-b6ab-15be0a7cfc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import ReflectionAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd1a8071-c763-4dbf-8db7-60f9116f62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReflectionAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87c8cf16-0dfa-49b6-bc30-8f14bbe7860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_system_prompt = \"You are a frontend developer tasked with generating high quality Python code\"\n",
    "\n",
    "reflection_system_prompt = \"You are  an experienced frontend developer\"\n",
    "\n",
    "user_msg = \"Generate a Python implementation of chatGpt frontend only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a9a3e5b-9b45-4a27-b391-f78b57ff94f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m\n",
      "==================================================\n",
      "\u001b[35mSTEP 1/3\n",
      "\u001b[1m\u001b[36m==================================================\n",
      "\n",
      "\u001b[34m \n",
      "\n",
      "GENERATION\n",
      "\n",
      " **ChatGPT Frontend Implementation**\n",
      "======================================\n",
      "\n",
      "This implementation focuses on creating a basic frontend for a chatbot using Python and the Tkinter library for GUI. Please note that this is a simplified version and doesn't include the actual AI model or backend logic.\n",
      "\n",
      "**Required Libraries**\n",
      "----------------------\n",
      "\n",
      "* `tkinter` for GUI\n",
      "* `requests` for API calls (if you plan to integrate with a backend API)\n",
      "\n",
      "**Code**\n",
      "------\n",
      "\n",
      "```python\n",
      "import tkinter as tk\n",
      "from tkinter import scrolledtext\n",
      "\n",
      "class ChatGPTFrontend:\n",
      "    def __init__(self, root):\n",
      "        self.root = root\n",
      "        self.root.title(\"ChatGPT\")\n",
      "        self.root.geometry(\"500x600\")\n",
      "\n",
      "        # Chat window\n",
      "        self.chat_window = scrolledtext.ScrolledText(self.root, width=60, height=20)\n",
      "        self.chat_window.pack(padx=10, pady=10)\n",
      "\n",
      "        # Input field\n",
      "        self.input_field = tk.Text(self.root, width=50, height=5)\n",
      "        self.input_field.pack(padx=10, pady=10)\n",
      "\n",
      "        # Send button\n",
      "        self.send_button = tk.Button(self.root, text=\"Send\", command=self.send_message)\n",
      "        self.send_button.pack(padx=10, pady=10)\n",
      "\n",
      "    def send_message(self):\n",
      "        # Get the user's input\n",
      "        user_input = self.input_field.get(\"1.0\", \"end-1c\")\n",
      "\n",
      "        # Clear the input field\n",
      "        self.input_field.delete(\"1.0\", tk.END)\n",
      "\n",
      "        # Display the user's input in the chat window\n",
      "        self.chat_window.insert(tk.END, f\"User: {user_input}\\n\")\n",
      "\n",
      "        # Simulate a response from the AI (replace with actual API call)\n",
      "        response = self.get_response(user_input)\n",
      "\n",
      "        # Display the AI's response in the chat window\n",
      "        self.chat_window.insert(tk.END, f\"AI: {response}\\n\")\n",
      "        self.chat_window.see(tk.END)\n",
      "\n",
      "    def get_response(self, user_input):\n",
      "        # Simulate a response from the AI (replace with actual API call)\n",
      "        # For demonstration purposes, return a simple response\n",
      "        return \"I'm happy to help you with that!\"\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    root = tk.Tk()\n",
      "    app = ChatGPTFrontend(root)\n",
      "    root.mainloop()\n",
      "```\n",
      "\n",
      "**Explanation**\n",
      "---------------\n",
      "\n",
      "1. The code creates a simple GUI with a chat window, input field, and send button.\n",
      "2. When the user clicks the send button, the `send_message` method is called.\n",
      "3. This method gets the user's input, clears the input field, and displays the user's input in the chat window.\n",
      "4. It then simulates a response from the AI by calling the `get_response` method (replace with actual API call).\n",
      "5. The AI's response is displayed in the chat window.\n",
      "6. The `get_response` method is a placeholder for the actual AI model or backend API.\n",
      "\n",
      "**Next Steps**\n",
      "--------------\n",
      "\n",
      "1. Integrate with a backend API or AI model to generate actual responses.\n",
      "2. Enhance the GUI with additional features, such as user authentication or conversation history.\n",
      "3. Improve the overall user experience and usability of the chat interface.\n",
      "\n",
      "Note: This is a simplified example and is not intended for production use without further development and testing.\n",
      "\u001b[32m \n",
      "\n",
      "REFLECTION\n",
      "\n",
      " **Critique and Recommendations**\n",
      "-------------------------------\n",
      "\n",
      "The provided code is a good start for a basic chatbot frontend using Python and Tkinter. However, there are several areas that can be improved for better functionality, usability, and maintainability. Here are some critiques and recommendations:\n",
      "\n",
      "1. **Error Handling**: The code does not handle any potential errors that may occur during execution. For example, if the user input is empty, the `send_message` method will still attempt to process it. Add try-except blocks to handle such scenarios.\n",
      "2. **Code Organization**: The `ChatGPTFrontend` class is responsible for both GUI creation and business logic. Consider separating these concerns into different classes or modules for better maintainability.\n",
      "3. **Code Duplication**: The `send_message` method clears the input field and displays the user's input in the chat window. These actions can be extracted into separate methods to avoid code duplication.\n",
      "4. **Response Generation**: The `get_response` method is a placeholder for the actual AI model or backend API. Consider using a more robust library or framework for natural language processing (NLP) tasks.\n",
      "5. **User Experience**: The chat interface is basic and can be improved for better user experience. Consider adding features like conversation history, user authentication, and emoticon support.\n",
      "6. **Testing**: The code lacks unit tests or integration tests to ensure its correctness and robustness. Consider using a testing framework like unittest or pytest to write tests for the code.\n",
      "7. **Code Style**: The code follows the PEP 8 style guide, but some improvements can be made. For example, consider using type hints for function parameters and return types.\n",
      "8. **Security**: The code does not handle any security concerns, such as input validation or sanitization. Consider adding measures to prevent potential security vulnerabilities.\n",
      "\n",
      "**Recommendations**\n",
      "-------------------\n",
      "\n",
      "1. **Refactor the code**: Separate the GUI creation and business logic into different classes or modules.\n",
      "2. **Add error handling**: Implement try-except blocks to handle potential errors during execution.\n",
      "3. **Improve code organization**: Extract methods for clearing the input field and displaying user input in the chat window.\n",
      "4. **Use a robust NLP library**: Consider using a library like NLTK or spaCy for NLP tasks.\n",
      "5. **Enhance user experience**: Add features like conversation history, user authentication, and emoticon support.\n",
      "6. **Write tests**: Use a testing framework to write unit tests or integration tests for the code.\n",
      "7. **Improve code style**: Use type hints and follow the PEP 8 style guide for better code readability.\n",
      "8. **Address security concerns**: Implement input validation and sanitization to prevent potential security vulnerabilities.\n",
      "\n",
      "Since there are areas to be improved, the output is not <OK>. \n",
      "\n",
      "Here is a list of critiques and recommendations for the user's content:\n",
      "* Error Handling: Add try-except blocks to handle potential errors.\n",
      "* Code Organization: Separate the GUI creation and business logic into different classes or modules.\n",
      "* Code Duplication: Extract methods for clearing the input field and displaying user input in the chat window.\n",
      "* Response Generation: Use a more robust library or framework for NLP tasks.\n",
      "* User Experience: Add features like conversation history, user authentication, and emoticon support.\n",
      "* Testing: Write unit tests or integration tests for the code.\n",
      "* Code Style: Use type hints and follow the PEP 8 style guide for better code readability.\n",
      "* Security: Implement input validation and sanitization to prevent potential security vulnerabilities.\n",
      "\u001b[31m \n",
      "\n",
      "Stop Sequence found. Stopping the reflection loop ... \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_response = agent.run(\n",
    "    user_msg=user_msg,\n",
    "    generation_system_prompt=generation_system_prompt,\n",
    "    reflection_system_prompt=reflection_system_prompt,\n",
    "    n_steps=3,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b69d182-d12e-40bb-8dfb-cbc8903218a1",
   "metadata": {},
   "source": [
    "## Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e4663cd-61dd-4a38-866a-f032045a444a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**ChatGPT Frontend Implementation**\n",
       "======================================\n",
       "\n",
       "This implementation focuses on creating a basic frontend for a chatbot using Python and the Tkinter library for GUI. Please note that this is a simplified version and doesn't include the actual AI model or backend logic.\n",
       "\n",
       "**Required Libraries**\n",
       "----------------------\n",
       "\n",
       "* `tkinter` for GUI\n",
       "* `requests` for API calls (if you plan to integrate with a backend API)\n",
       "\n",
       "**Code**\n",
       "------\n",
       "\n",
       "```python\n",
       "import tkinter as tk\n",
       "from tkinter import scrolledtext\n",
       "\n",
       "class ChatGPTFrontend:\n",
       "    def __init__(self, root):\n",
       "        self.root = root\n",
       "        self.root.title(\"ChatGPT\")\n",
       "        self.root.geometry(\"500x600\")\n",
       "\n",
       "        # Chat window\n",
       "        self.chat_window = scrolledtext.ScrolledText(self.root, width=60, height=20)\n",
       "        self.chat_window.pack(padx=10, pady=10)\n",
       "\n",
       "        # Input field\n",
       "        self.input_field = tk.Text(self.root, width=50, height=5)\n",
       "        self.input_field.pack(padx=10, pady=10)\n",
       "\n",
       "        # Send button\n",
       "        self.send_button = tk.Button(self.root, text=\"Send\", command=self.send_message)\n",
       "        self.send_button.pack(padx=10, pady=10)\n",
       "\n",
       "    def send_message(self):\n",
       "        # Get the user's input\n",
       "        user_input = self.input_field.get(\"1.0\", \"end-1c\")\n",
       "\n",
       "        # Clear the input field\n",
       "        self.input_field.delete(\"1.0\", tk.END)\n",
       "\n",
       "        # Display the user's input in the chat window\n",
       "        self.chat_window.insert(tk.END, f\"User: {user_input}\\n\")\n",
       "\n",
       "        # Simulate a response from the AI (replace with actual API call)\n",
       "        response = self.get_response(user_input)\n",
       "\n",
       "        # Display the AI's response in the chat window\n",
       "        self.chat_window.insert(tk.END, f\"AI: {response}\\n\")\n",
       "        self.chat_window.see(tk.END)\n",
       "\n",
       "    def get_response(self, user_input):\n",
       "        # Simulate a response from the AI (replace with actual API call)\n",
       "        # For demonstration purposes, return a simple response\n",
       "        return \"I'm happy to help you with that!\"\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    root = tk.Tk()\n",
       "    app = ChatGPTFrontend(root)\n",
       "    root.mainloop()\n",
       "```\n",
       "\n",
       "**Explanation**\n",
       "---------------\n",
       "\n",
       "1. The code creates a simple GUI with a chat window, input field, and send button.\n",
       "2. When the user clicks the send button, the `send_message` method is called.\n",
       "3. This method gets the user's input, clears the input field, and displays the user's input in the chat window.\n",
       "4. It then simulates a response from the AI by calling the `get_response` method (replace with actual API call).\n",
       "5. The AI's response is displayed in the chat window.\n",
       "6. The `get_response` method is a placeholder for the actual AI model or backend API.\n",
       "\n",
       "**Next Steps**\n",
       "--------------\n",
       "\n",
       "1. Integrate with a backend API or AI model to generate actual responses.\n",
       "2. Enhance the GUI with additional features, such as user authentication or conversation history.\n",
       "3. Improve the overall user experience and usability of the chat interface.\n",
       "\n",
       "Note: This is a simplified example and is not intended for production use without further development and testing."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(final_response, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8bf0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini-rag-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
