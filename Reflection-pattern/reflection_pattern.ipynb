{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1bc453d-c8d3-4503-b3da-52120ad92c74",
   "metadata": {
    "tags": []
   },
   "source": [
    "# world of agents\n",
    "## Reflection Pattern\n",
    "\n",
    "The first pattern we are going to implement is the **reflection pattern**. \n",
    "\n",
    "This pattern allows the LLM to reflect and critique its outputs, following the next steps:\n",
    "\n",
    "1. The LLM **generates** a candidate output. If you look at the diagram above, it happens inside the **\"Generate\"** box.\n",
    "2. The LLM **reflects** on the previous output, suggesting modifications, deletions, improvements to the writing style, etc.\n",
    "3. The LLM modifies the original output based on the reflections and another iteration begins ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898c34d-de9a-4970-b7f4-3d86b69d45a7",
   "metadata": {},
   "source": [
    "## Generation Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4d7b7-40bf-43b9-a626-2a11d5529ac8",
   "metadata": {},
   "source": [
    "### dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fdbf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install groq\n",
    "pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96731d2f-a079-4e41-9756-220f02d4ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "# Remember to load the environment variables. You should have the Groq API Key in there :)\n",
    "load_dotenv()\n",
    "\n",
    "client = Groq()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e644a635-e035-44e2-8c25-cee0f2b56556",
   "metadata": {},
   "source": [
    "We will start the **\"generation\"** chat history with the system prompt, as we said before. In this case, let the LLM act like a mathematician."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12467256-c741-495a-9923-439c1fcf270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_chat_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a front end developer tasked with generating high quality Python code.\"\n",
    "        \"Your task is to Generate the best content possible for the user's request. If the user provides critique,\" \n",
    "        \"respond with a revised version of your previous attempt.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43149b4f-54db-455f-9d39-6ad2f5c52b94",
   "metadata": {},
   "source": [
    "Now, as the user, we are going to ask the LLM to generate an implementation of the **Merge Sort** algorithm. Just add a new message with the **user** role to the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742e7bd-4857-4ed1-a96b-37098d448bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_chat_history.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Generate a Python implementation of front end web app like chatgpt\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df1bffe-375f-4a9a-8433-e217eb94aea2",
   "metadata": {},
   "source": [
    "Let's generate the first version of the essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff984277-733c-4495-b7fd-0669393380b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend_code = client.chat.completions.create(\n",
    "    messages=generation_chat_history,\n",
    "    model=\"llama3-70b-8192\"\n",
    ").choices[0].message.content\n",
    "\n",
    "generation_chat_history.append(\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": frontend_code\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03f208b-2234-4fd1-a02b-f4fff06c01a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_markdown(frontend_code, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04ebe5-0573-4520-a529-aff22d486b7d",
   "metadata": {},
   "source": [
    "## Reflection Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93c928-d585-48af-a74c-a5b8d84593c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reflection_chat_history = [\n",
    "    {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You ar  an experienced frontend devloper. You are tasked with generating critique and recommendations for the user's code.\"\n",
    "    \"make sure to code the certain task only without any additions like adding irrelavnt features,\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498175f-b3f9-40af-92a3-d5b36d77d1cf",
   "metadata": {},
   "source": [
    "The user message, in this case,  is the essay generated in the previous step. We simply add the `mergesort_code` to the `reflection_chat_history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af1a73-4d91-40e8-a9bc-c34d32b2ab82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reflection_chat_history.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": frontend_code\n",
    "\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa994c8-3612-47b0-9571-e21d0d73d896",
   "metadata": {},
   "source": [
    "Now, let's generate a critique to the Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fee42f-d47a-41b1-a40d-7208ba76ce98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "critique = client.chat.completions.create(\n",
    "    messages=reflection_chat_history,\n",
    "    model=\"llama3-70b-8192\"\n",
    ").choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef3203-c7f1-407f-8b9b-4e8ae140a4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_markdown(critique, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df433b0-d662-4378-895e-6b09dd3201bc",
   "metadata": {},
   "source": [
    "Finally, we just need to add this *critique* to the `generation_chat_history`, in this case, as the `user` role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a85bb3-cf6a-4576-8caf-cd41e602a1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_chat_history.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": critique\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1aefa-8454-41ab-af40-2675f340a577",
   "metadata": {},
   "source": [
    "## Generation Step (II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d845cf-51c3-4cfd-b6a7-1b970413f6db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "revised_code = client.chat.completions.create(\n",
    "    messages=generation_chat_history,\n",
    "    model=\"llama3-70b-8192\"\n",
    ").choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14eaa8-f501-4efc-997f-8564ec8dccd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_markdown(revised_code, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2cf5b-d083-435c-914a-3ff484d53473",
   "metadata": {},
   "source": [
    "## Implementing a class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9a9e6-29f3-4adf-863e-c49fbb9a6b44",
   "metadata": {},
   "source": [
    "Now that you understand the underlying loop of the Reflection Agent, let's implement this agent as a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1658b881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 70E8-0B08\n",
      "\n",
      " Directory of c:\\Users\\moman\\OneDrive\\Desktop\\agents\\agentic-patterns-course\\Reflection_agent\n",
      "\n",
      "09/05/2025  05:29 PM    <DIR>          .\n",
      "09/05/2025  05:22 PM    <DIR>          ..\n",
      "08/05/2025  06:53 PM                73 .env\n",
      "08/05/2025  05:25 PM                49 __init__.py\n",
      "09/05/2025  05:28 PM    <DIR>          reflection_pattern\n",
      "09/05/2025  05:34 PM            30,053 reflection_pattern.ipynb\n",
      "09/05/2025  05:29 PM    <DIR>          utils\n",
      "               3 File(s)         30,175 bytes\n",
      "               4 Dir(s)   1,040,412,672 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f951fe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'Reflection_agent'\n",
      "c:\\Users\\moman\\OneDrive\\Desktop\\agents\\agentic-patterns-course\\Reflection_agent\n"
     ]
    }
   ],
   "source": [
    "cd Reflection_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f904241-29a1-4519-b6ab-15be0a7cfc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import ReflectionAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1a8071-c763-4dbf-8db7-60f9116f62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReflectionAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c8cf16-0dfa-49b6-bc30-8f14bbe7860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_system_prompt = \"You are a frontend developer tasked with generating high quality Python code\"\n",
    "\n",
    "reflection_system_prompt = \"You are  an experienced frontend developer\"\n",
    "\n",
    "user_msg = \"Generate a Python implementation of chatGpt frontend only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9a3e5b-9b45-4a27-b391-f78b57ff94f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m\n",
      "==================================================\n",
      "\u001b[35mSTEP 1/3\n",
      "\u001b[1m\u001b[36m==================================================\n",
      "\n",
      "\u001b[34m \n",
      "\n",
      "GENERATION\n",
      "\n",
      " **ChatGPT Frontend Implementation in Python**\n",
      "======================================================\n",
      "\n",
      "In this implementation, we will focus on creating a simple frontend for the ChatGPT model using Python and the Tkinter library for the graphical user interface.\n",
      "\n",
      "**Prerequisites**\n",
      "---------------\n",
      "\n",
      "* Python 3.8+\n",
      "* Tkinter library (comes pre-installed with Python)\n",
      "\n",
      "**Code**\n",
      "------\n",
      "\n",
      "```python\n",
      "import tkinter as tk\n",
      "from tkinter import scrolledtext\n",
      "import requests\n",
      "\n",
      "class ChatGPT:\n",
      "    def __init__(self, root):\n",
      "        self.root = root\n",
      "        self.root.title(\"ChatGPT\")\n",
      "        self.root.geometry(\"800x600\")\n",
      "\n",
      "        # Create frames\n",
      "        self.frame_input = tk.Frame(self.root)\n",
      "        self.frame_input.pack(fill=\"x\")\n",
      "\n",
      "        self.frame_output = tk.Frame(self.root)\n",
      "        self.frame_output.pack(fill=\"both\", expand=True)\n",
      "\n",
      "        # Create input field\n",
      "        self.input_field = tk.Text(self.frame_input, height=5)\n",
      "        self.input_field.pack(fill=\"x\", padx=10, pady=10)\n",
      "\n",
      "        # Create send button\n",
      "        self.send_button = tk.Button(self.frame_input, text=\"Send\", command=self.send_message)\n",
      "        self.send_button.pack(fill=\"x\", padx=10, pady=10)\n",
      "\n",
      "        # Create output field\n",
      "        self.output_field = scrolledtext.ScrolledText(self.frame_output)\n",
      "        self.output_field.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
      "\n",
      "    def send_message(self):\n",
      "        # Get input text\n",
      "        input_text = self.input_field.get(\"1.0\", \"end-1c\")\n",
      "\n",
      "        # Send request to API (replace with your own API endpoint)\n",
      "        url = \"https://api.example.com/chatgpt\"\n",
      "        data = {\"message\": input_text}\n",
      "        response = requests.post(url, json=data)\n",
      "\n",
      "        # Get response text\n",
      "        response_text = response.json()[\"response\"]\n",
      "\n",
      "        # Display response text\n",
      "        self.output_field.insert(\"end\", \"You: \" + input_text + \"\\n\")\n",
      "        self.output_field.insert(\"end\", \"ChatGPT: \" + response_text + \"\\n\")\n",
      "        self.output_field.see(\"end\")\n",
      "\n",
      "        # Clear input field\n",
      "        self.input_field.delete(\"1.0\", \"end\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    root = tk.Tk()\n",
      "    chatgpt = ChatGPT(root)\n",
      "    root.mainloop()\n",
      "```\n",
      "\n",
      "**Explanation**\n",
      "--------------\n",
      "\n",
      "This implementation creates a simple graphical user interface with an input field, a send button, and an output field. When the user clicks the send button, the input text is sent to a fictional API endpoint (replace with your own API endpoint) and the response text is displayed in the output field.\n",
      "\n",
      "**Example Use Case**\n",
      "--------------------\n",
      "\n",
      "1. Run the code.\n",
      "2. Type a message in the input field (e.g., \"Hello, how are you?\").\n",
      "3. Click the send button.\n",
      "4. The response text will be displayed in the output field (e.g., \"I'm doing well, thank you for asking!\").\n",
      "\n",
      "**Note**\n",
      "-------\n",
      "\n",
      "This implementation does not include any actual AI or natural language processing capabilities. It is simply a frontend for a fictional API endpoint. You will need to replace the `url` variable with your own API endpoint to use this implementation with a real ChatGPT model.\n",
      "\u001b[32m \n",
      "\n",
      "REFLECTION\n",
      "\n",
      " ### Code Review and Recommendations\n",
      "\n",
      "The provided code is a basic implementation of a ChatGPT frontend using Python and Tkinter. Here are some critiques and recommendations for improvement:\n",
      "\n",
      "#### Critiques:\n",
      "\n",
      "1. **Error Handling**: The code does not handle potential errors that may occur during the API request, such as network errors or invalid responses. Consider adding try-except blocks to handle these scenarios.\n",
      "2. **API Endpoint**: The code uses a fictional API endpoint (`https://api.example.com/chatgpt`). You should replace this with a real API endpoint that supports the ChatGPT model.\n",
      "3. **Input Validation**: The code does not validate the user's input. Consider adding checks to ensure that the input is not empty or too long.\n",
      "4. **Response Validation**: The code assumes that the API response will always contain a \"response\" key. Consider adding checks to handle cases where the response is invalid or missing required keys.\n",
      "5. **Code Organization**: The code mixes GUI logic with API request logic. Consider separating these concerns into different functions or classes.\n",
      "\n",
      "#### Recommendations:\n",
      "\n",
      "1. **Improve Error Handling**:\n",
      "   * Add try-except blocks to handle potential errors during API requests.\n",
      "   * Display error messages to the user in case of errors.\n",
      "\n",
      "2. **Enhance Input Validation**:\n",
      "   * Add checks to ensure that the user's input is not empty or too long.\n",
      "   * Display error messages to the user in case of invalid input.\n",
      "\n",
      "3. **Improve Response Validation**:\n",
      "   * Add checks to ensure that the API response is valid and contains the required keys.\n",
      "   * Display error messages to the user in case of invalid responses.\n",
      "\n",
      "4. **Separate Concerns**:\n",
      "   * Create separate functions or classes for GUI logic and API request logic.\n",
      "   * Use a more modular approach to make the code easier to maintain and extend.\n",
      "\n",
      "5. **Add Logging**:\n",
      "   * Consider adding logging statements to track important events, such as API requests and responses.\n",
      "   * Use a logging library like Python's built-in `logging` module.\n",
      "\n",
      "6. **Improve Code Style**:\n",
      "   * Follow PEP 8 guidelines for code style and formatting.\n",
      "   * Use consistent naming conventions and indentation.\n",
      "\n",
      "Here is an updated version of the code that addresses some of these concerns:\n",
      "```python\n",
      "import tkinter as tk\n",
      "from tkinter import scrolledtext\n",
      "import requests\n",
      "import logging\n",
      "\n",
      "# Set up logging\n",
      "logging.basicConfig(level=logging.INFO)\n",
      "\n",
      "class ChatGPT:\n",
      "    def __init__(self, root):\n",
      "        self.root = root\n",
      "        self.root.title(\"ChatGPT\")\n",
      "        self.root.geometry(\"800x600\")\n",
      "\n",
      "        # Create frames\n",
      "        self.frame_input = tk.Frame(self.root)\n",
      "        self.frame_input.pack(fill=\"x\")\n",
      "\n",
      "        self.frame_output = tk.Frame(self.root)\n",
      "        self.frame_output.pack(fill=\"both\", expand=True)\n",
      "\n",
      "        # Create input field\n",
      "        self.input_field = tk.Text(self.frame_input, height=5)\n",
      "        self.input_field.pack(fill=\"x\", padx=10, pady=10)\n",
      "\n",
      "        # Create send button\n",
      "        self.send_button = tk.Button(self.frame_input, text=\"Send\", command=self.send_message)\n",
      "        self.send_button.pack(fill=\"x\", padx=10, pady=10)\n",
      "\n",
      "        # Create output field\n",
      "        self.output_field = scrolledtext.ScrolledText(self.frame_output)\n",
      "        self.output_field.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
      "\n",
      "    def send_message(self):\n",
      "        # Get input text\n",
      "        input_text = self.input_field.get(\"1.0\", \"end-1c\")\n",
      "\n",
      "        # Validate input text\n",
      "        if not input_text:\n",
      "            self.output_field.insert(\"end\", \"Error: Input is empty\\n\")\n",
      "            return\n",
      "\n",
      "        # Send request to API\n",
      "        try:\n",
      "            url = \"https://api.example.com/chatgpt\"\n",
      "            data = {\"message\": input_text}\n",
      "            response = requests.post(url, json=data)\n",
      "            response.raise_for_status()\n",
      "        except requests.exceptions.RequestException as e:\n",
      "            logging.error(f\"Error sending request: {e}\")\n",
      "            self.output_field.insert(\"end\", f\"Error: {e}\\n\")\n",
      "            return\n",
      "\n",
      "        # Validate response\n",
      "        try:\n",
      "            response_text = response.json()[\"response\"]\n",
      "        except (KeyError, ValueError) as e:\n",
      "            logging.error(f\"Error parsing response: {e}\")\n",
      "            self.output_field.insert(\"end\", f\"Error: {e}\\n\")\n",
      "            return\n",
      "\n",
      "        # Display response text\n",
      "        self.output_field.insert(\"end\", \"You: \" + input_text + \"\\n\")\n",
      "        self.output_field.insert(\"end\", \"ChatGPT: \" + response_text + \"\\n\")\n",
      "        self.output_field.see(\"end\")\n",
      "\n",
      "        # Clear input field\n",
      "        self.input_field.delete(\"1.0\", \"end\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    root = tk.Tk()\n",
      "    chatgpt = ChatGPT(root)\n",
      "    root.mainloop()\n",
      "```\n",
      "Since the provided code has some issues that need to be addressed, the output is not `<OK>`. Instead, the above recommendations and updated code should be considered to improve the code quality and functionality.\n",
      "\u001b[31m \n",
      "\n",
      "Stop Sequence found. Stopping the reflection loop ... \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_response = agent.run(\n",
    "    user_msg=user_msg,\n",
    "    generation_system_prompt=generation_system_prompt,\n",
    "    reflection_system_prompt=reflection_system_prompt,\n",
    "    n_steps=3,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b69d182-d12e-40bb-8dfb-cbc8903218a1",
   "metadata": {},
   "source": [
    "## Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e4663cd-61dd-4a38-866a-f032045a444a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**ChatGPT Frontend Implementation in Python**\n",
       "======================================================\n",
       "\n",
       "In this implementation, we will focus on creating a simple frontend for the ChatGPT model using Python and the Tkinter library for the graphical user interface.\n",
       "\n",
       "**Prerequisites**\n",
       "---------------\n",
       "\n",
       "* Python 3.8+\n",
       "* Tkinter library (comes pre-installed with Python)\n",
       "\n",
       "**Code**\n",
       "------\n",
       "\n",
       "```python\n",
       "import tkinter as tk\n",
       "from tkinter import scrolledtext\n",
       "import requests\n",
       "\n",
       "class ChatGPT:\n",
       "    def __init__(self, root):\n",
       "        self.root = root\n",
       "        self.root.title(\"ChatGPT\")\n",
       "        self.root.geometry(\"800x600\")\n",
       "\n",
       "        # Create frames\n",
       "        self.frame_input = tk.Frame(self.root)\n",
       "        self.frame_input.pack(fill=\"x\")\n",
       "\n",
       "        self.frame_output = tk.Frame(self.root)\n",
       "        self.frame_output.pack(fill=\"both\", expand=True)\n",
       "\n",
       "        # Create input field\n",
       "        self.input_field = tk.Text(self.frame_input, height=5)\n",
       "        self.input_field.pack(fill=\"x\", padx=10, pady=10)\n",
       "\n",
       "        # Create send button\n",
       "        self.send_button = tk.Button(self.frame_input, text=\"Send\", command=self.send_message)\n",
       "        self.send_button.pack(fill=\"x\", padx=10, pady=10)\n",
       "\n",
       "        # Create output field\n",
       "        self.output_field = scrolledtext.ScrolledText(self.frame_output)\n",
       "        self.output_field.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
       "\n",
       "    def send_message(self):\n",
       "        # Get input text\n",
       "        input_text = self.input_field.get(\"1.0\", \"end-1c\")\n",
       "\n",
       "        # Send request to API (replace with your own API endpoint)\n",
       "        url = \"https://api.example.com/chatgpt\"\n",
       "        data = {\"message\": input_text}\n",
       "        response = requests.post(url, json=data)\n",
       "\n",
       "        # Get response text\n",
       "        response_text = response.json()[\"response\"]\n",
       "\n",
       "        # Display response text\n",
       "        self.output_field.insert(\"end\", \"You: \" + input_text + \"\\n\")\n",
       "        self.output_field.insert(\"end\", \"ChatGPT: \" + response_text + \"\\n\")\n",
       "        self.output_field.see(\"end\")\n",
       "\n",
       "        # Clear input field\n",
       "        self.input_field.delete(\"1.0\", \"end\")\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    root = tk.Tk()\n",
       "    chatgpt = ChatGPT(root)\n",
       "    root.mainloop()\n",
       "```\n",
       "\n",
       "**Explanation**\n",
       "--------------\n",
       "\n",
       "This implementation creates a simple graphical user interface with an input field, a send button, and an output field. When the user clicks the send button, the input text is sent to a fictional API endpoint (replace with your own API endpoint) and the response text is displayed in the output field.\n",
       "\n",
       "**Example Use Case**\n",
       "--------------------\n",
       "\n",
       "1. Run the code.\n",
       "2. Type a message in the input field (e.g., \"Hello, how are you?\").\n",
       "3. Click the send button.\n",
       "4. The response text will be displayed in the output field (e.g., \"I'm doing well, thank you for asking!\").\n",
       "\n",
       "**Note**\n",
       "-------\n",
       "\n",
       "This implementation does not include any actual AI or natural language processing capabilities. It is simply a frontend for a fictional API endpoint. You will need to replace the `url` variable with your own API endpoint to use this implementation with a real ChatGPT model."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(final_response, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8bf0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini-rag-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
